{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# model = load_model('mask_detection_model.h5')\n",
    "model = load_model('model2-007.h5')\n",
    "\n",
    "labels = ['Without Mask', 'With Mask']\n",
    "\n",
    "colors = [(0, 0, 255), (0, 255, 0)]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "\n",
    "        face = cv2.resize(face, (150, 150))\n",
    "\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "        face = face / 255.0\n",
    "\n",
    "        pred = model.predict(face)[0]\n",
    "\n",
    "        label = labels[pred.argmax()]\n",
    "        score = pred[pred.argmax()]\n",
    "\n",
    "        print(label, \" \", score)\n",
    "        color = colors[pred.argmax()]\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(frame, label + ' ({:.2f}%)'.format(score*100), (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    cv2.imshow('Face Mask Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 274 650 410\n",
      "319 274 640 408\n",
      "317 274 655 404\n",
      "318 274 645 403\n",
      "318 277 659 402\n",
      "318 277 650 399\n",
      "318 277 662 401\n",
      "319 277 651 399\n",
      "316 275 668 406\n",
      "317 275 658 405\n",
      "318 275 663 406\n",
      "318 275 655 404\n",
      "318 273 664 406\n",
      "318 273 656 403\n",
      "319 273 667 407\n",
      "320 273 658 404\n",
      "318 275 665 409\n",
      "319 275 655 406\n",
      "318 274 670 406\n",
      "318 274 660 403\n",
      "317 273 666 408\n",
      "317 273 657 405\n",
      "318 273 668 409\n",
      "318 273 658 406\n",
      "318 273 674 407\n",
      "318 273 664 403\n",
      "318 272 667 409\n",
      "318 272 657 405\n",
      "317 273 661 409\n",
      "318 272 651 406\n",
      "318 273 664 409\n",
      "318 273 655 407\n",
      "318 272 658 414\n",
      "318 272 650 410\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "net = cv2.dnn.readNet('yolov4.weights', 'yolov4.cfg')\n",
    "\n",
    "labels = ['Without Mask', 'With Mask']\n",
    "\n",
    "colors = [(0, 255, 225), (0, 255, 0)]\n",
    "\n",
    "model = load_model('mask_detection_model.h5')\n",
    "\n",
    "conf_thresh = 0.8\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    for detection in detections:\n",
    "        class_id = np.argmax(detection[5:])\n",
    "        score = detection[class_id + 5]\n",
    "        if score > conf_thresh:\n",
    "            box = detection[:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "            (x, y, w, h) = box.astype('int')\n",
    "\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "\n",
    "            face = cv2.resize(face, (150, 150))\n",
    "\n",
    "            face = np.expand_dims(face, axis=0)\n",
    "            face = face / 255.0\n",
    "\n",
    "            pred = model.predict(face)[0]\n",
    "\n",
    "            label = labels[pred.argmax()]\n",
    "            score = pred[pred.argmax()]\n",
    "\n",
    "            color = colors[pred.argmax()]\n",
    "            print(x,y,w,h)\n",
    "            cv2.rectangle(frame, (int(x/2), int(y/2)), (int(x + x*0.5), int(y + y*0.5)), color, 2)\n",
    "            cv2.putText(frame, label + ' ({:.2f}%)'.format(score*100), (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    cv2.imshow('Face Mask Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
